{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ëª¨ë¸ ì„¤ëª…"
      ],
      "metadata": {
        "id": "GbufoPeItBAy"
      },
      "id": "GbufoPeItBAy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì¢‹ì•„, íŒ€ì›ë“¤ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ **`perfume_model_api.ipynb` ì „ì²´ êµ¬ì¡°**ë¥¼ ê° ë¸”ë¡ë§ˆë‹¤ ì„¤ëª…ì„ ë¶™ì—¬ ì •ë¦¬í•´ì¤„ê²Œ. ì´ê±´ ë§ˆí¬ë‹¤ìš´ ì…€ë¡œ ë…¸íŠ¸ë¶ì— ë¶™ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥í•´.\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ’¡ í–¥ìˆ˜ ì¶”ì²œ ëª¨ë¸ ì „ì²´ êµ¬ì¡° ì„¤ëª… (`perfume_model_api.ipynb`)\n",
        "\n",
        "## 1. âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì¬í˜„ì„± ê³ ì •\n",
        "\n",
        "```python\n",
        "import os, random, pickle\n",
        "import numpy as np\n",
        "...\n",
        "tf.random.set_seed(42)\n",
        "```\n",
        "\n",
        "* ë°ì´í„° ì²˜ë¦¬ ë° ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ ,\n",
        "* ê²°ê³¼ì˜ **ì¼ê´€ì„±**ì„ ìœ„í•´ seedë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. ğŸ“¦ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
        "\n",
        "```python\n",
        "df = pd.read_csv('./data/dataset.csv')\n",
        "...\n",
        "df['notes'] = df['notes'].apply(clean_notes)\n",
        "```\n",
        "\n",
        "* `.csv` íŒŒì¼ì—ì„œ í–¥ìˆ˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³ ,\n",
        "* `notes` í•„ë“œë¥¼ ì •ì œí•©ë‹ˆë‹¤ (ë¶ˆí•„ìš”í•œ ê¸°í˜¸/ê³µë°± ì œê±° ë“±).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. ğŸ§ª í–¥ë£Œ ë²¡í„°í™”\n",
        "\n",
        "```python\n",
        "note_vectorizer = CountVectorizer(token_pattern=r'[^,]+')\n",
        "...\n",
        "note_df = pd.DataFrame(...)\n",
        "```\n",
        "\n",
        "* `notes`(í–¥ë£Œ ëª©ë¡)ë¥¼ Bag-of-Words ë°©ì‹ìœ¼ë¡œ ë²¡í„°í™”í•©ë‹ˆë‹¤.\n",
        "* ê° í–¥ìˆ˜ë§ˆë‹¤ í–¥ë£Œ ì¶œí˜„ ì—¬ë¶€ê°€ ë²¡í„°ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. ğŸ§  ì…ë ¥ê°’ ì¸ì½”ë”©\n",
        "\n",
        "```python\n",
        "encoder = OrdinalEncoder()\n",
        "...\n",
        "X = encoder.transform(...)\n",
        "```\n",
        "\n",
        "* ì„±ë³„, ê³„ì ˆ, ì‹œê°„ëŒ€ ë“±ì˜ **ì¹´í…Œê³ ë¦¬ íŠ¹ì„±**ì„ ìˆ«ìë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤.\n",
        "* OneHotì´ ì•„ë‹Œ **OrdinalEncoder**ë¥¼ ì‚¬ìš©í•´ ì˜ë¯¸ë¡ ì  ê±°ë¦¬ ë°˜ì˜.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. ğŸ§© í•™ìŠµ ë°ì´í„° ë¶„í•  ë° í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
        "\n",
        "```python\n",
        "X_train, X_val, y_train, y_val = ...\n",
        "class_weights = compute_class_weight(...)\n",
        "```\n",
        "\n",
        "* ì „ì²´ ë°ì´í„°ë¥¼ **í•™ìŠµ/ê²€ì¦**ìœ¼ë¡œ ë‚˜ëˆ„ê³ ,\n",
        "* ë¶ˆê· í˜•í•œ ê°ì • í´ë˜ìŠ¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜**ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. ğŸ—ï¸ ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
        "\n",
        "```python\n",
        "model = Sequential([...])\n",
        "model.compile(...)\n",
        "model.fit(...)\n",
        "```\n",
        "\n",
        "* ì‹¬í”Œí•œ Dense(64) êµ¬ì¡°ì˜ **MLP ëª¨ë¸**ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "* `EarlyStopping`ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€, í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. ğŸ§¾ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
        "\n",
        "```python\n",
        "y_pred = ...\n",
        "results = {\n",
        "    \"classification_report\": ...,\n",
        "    \"macro_f1\": ...,\n",
        "    \"weighted_f1\": ...\n",
        "}\n",
        "```\n",
        "\n",
        "* ê²€ì¦ ë°ì´í„°ë¥¼ ì´ìš©í•´ **ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜**ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
        "* ì¶”í›„ ë¶„ì„ì„ ìœ„í•œ JSON í˜•íƒœë¡œ ì €ì¥.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. ğŸ’¾ ëª¨ë¸ ë° ë„êµ¬ ì €ì¥\n",
        "\n",
        "```python\n",
        "model.save(...)\n",
        "pickle.dump(...)\n",
        "note_df.to_csv(...)\n",
        "```\n",
        "\n",
        "* í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ ë° ì¸ì½”ë”, ë²¡í„°ë¼ì´ì €ë¥¼ `.keras`, `.pkl`, `.csv` í˜•íƒœë¡œ ì €ì¥.\n",
        "* API ì„œë²„ì—ì„œ ë°”ë¡œ ë¡œë”© ê°€ëŠ¥í•˜ê²Œ êµ¬ì„±ë¨.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. ğŸ” ê°ì • ì˜ˆì¸¡ í•¨ìˆ˜ (`predict_emotion`)\n",
        "\n",
        "```python\n",
        "def predict_emotion(user_input):\n",
        "    ...\n",
        "    return {\n",
        "        \"cluster\": pred,\n",
        "        \"description\": EMOTION_DESC[pred],\n",
        "        \"proba\": proba.tolist()\n",
        "    }\n",
        "```\n",
        "\n",
        "* ì‚¬ìš©ìì˜ íƒœê·¸ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ **ê°ì • í´ëŸ¬ìŠ¤í„°ë¥¼ ì˜ˆì¸¡**í•˜ê³ ,\n",
        "* ê°ì • ì„¤ëª…(`description`)ê³¼ í™•ë¥  ë¶„í¬(`proba`)ë¥¼ ë°˜í™˜.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. ğŸ“ ì£¼ìš” ë…¸íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ (`extract_notes`)\n",
        "\n",
        "```python\n",
        "def extract_notes(...):\n",
        "    ...\n",
        "    return ìƒìœ„ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸, 1ì°¨ ì¶”ì²œ í–¥ìˆ˜ ì¸ë±ìŠ¤\n",
        "```\n",
        "\n",
        "* ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°ì— ê¸°ë°˜í•´ **ëŒ€í‘œì ì¸ ë…¸íŠ¸ 15ê°œ**ë¥¼ ì¶”ì¶œ.\n",
        "* í–¥ìˆ˜ ë²¡í„° ê°„ ìœ ì‚¬ë„ë¥¼ í™œìš©í•´ **ì¤‘ë³µë˜ì§€ ì•ŠëŠ” í–¥ìˆ˜ 10ê°œ**ë„ ì„ íƒ.\n",
        "\n",
        "---\n",
        "\n",
        "## 11. ğŸŒ¸ í–¥ìˆ˜ ì¬ì¶”ì²œ í•¨ìˆ˜ (`recommend_perfumes`)\n",
        "\n",
        "```python\n",
        "def recommend_perfumes(...):\n",
        "    ...\n",
        "    return ì¶”ì²œ í–¥ìˆ˜ ë¦¬ìŠ¤íŠ¸ (JSON ë”•ì…”ë„ˆë¦¬)\n",
        "```\n",
        "\n",
        "* ì‚¬ìš©ìê°€ ì„ íƒí•œ **ë…¸íŠ¸ ì„ í˜¸ë„ ì ìˆ˜**ë¥¼ ë°›ì•„,\n",
        "* ê°ì • + ë…¸íŠ¸ ê¸°ë°˜ì˜ `final_score`ë¡œ 2ì°¨ í–¥ìˆ˜ ì¶”ì²œì„ ìˆ˜í–‰.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ì—°ë™ í¬ì¸íŠ¸ ìš”ì•½\n",
        "\n",
        "| ëª©ì         | ì„¤ëª…                                          |\n",
        "| --------- | ------------------------------------------- |\n",
        "| í”„ë¡ íŠ¸ ì…ë ¥    | `user_input`: íƒœê·¸ 6ê°œ                         |\n",
        "| 1ì°¨ í˜¸ì¶œ API | `/predict_emotion`: ê°ì • í´ëŸ¬ìŠ¤í„° + ì„¤ëª… + proba ë°˜í™˜ |\n",
        "| ë…¸íŠ¸ ì„ íƒ ì´í›„  | `/recommend_perfumes`: ì¶”ì²œ í–¥ìˆ˜ 10ê°œ ë°˜í™˜         |\n",
        "| ê²°ê³¼ í¬ë§·     | `JSON` í˜•íƒœë¡œ API ì‘ë‹µ ê°€ëŠ¥                        |\n",
        "\n",
        "---\n",
        "\n",
        "í•„ìš”í•˜ë©´ ì´ ì„¤ëª…ì„ `.ipynb` ë‚´ë¶€ ë§ˆí¬ë‹¤ìš´ ì…€ë¡œ ë§Œë“¤ì–´ì„œ ì¶”ê°€í•´ì¤„ ìˆ˜ ìˆì–´. ì›í•  ë•Œ ë§í•´ì¤˜!\n"
      ],
      "metadata": {
        "id": "nMQuy9tAtJeH"
      },
      "id": "nMQuy9tAtJeH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ëª¨ë¸"
      ],
      "metadata": {
        "id": "rRp9o7OssHRQ"
      },
      "id": "rRp9o7OssHRQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e3b339",
      "metadata": {
        "id": "02e3b339"
      },
      "outputs": [],
      "source": [
        "\n",
        "# perfume_model_api.ipynb\n",
        "# âœ… API ì—°ë™ìš©ìœ¼ë¡œ ë¦¬íŒ©í† ë§ë¨\n",
        "\n",
        "import os, random, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ì¬í˜„ì„± ê³ ì •\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "df = pd.read_csv('./data/dataset.csv')\n",
        "df['notes'] = df['notes'].fillna('').str.lower()\n",
        "\n",
        "def clean_notes(raw_notes):\n",
        "    notes = [n.strip() for n in raw_notes.split(',')]\n",
        "    return ', '.join([n for n in notes if len(n) > 0 and len(n) < 40])\n",
        "\n",
        "df['notes'] = df['notes'].apply(clean_notes)\n",
        "\n",
        "note_vectorizer = CountVectorizer(token_pattern=r'[^,]+')\n",
        "note_matrix = note_vectorizer.fit_transform(df['notes'])\n",
        "note_df = pd.DataFrame(note_matrix.toarray(), columns=note_vectorizer.get_feature_names_out())\n",
        "\n",
        "# ì¸ì½”ë”© ë° ë¶„í• \n",
        "encoder = OrdinalEncoder()\n",
        "X_input = df[['gender', 'season_tags', 'time_tags', 'desired_impression', 'activity', 'weather']]\n",
        "encoder.fit(X_input.values)\n",
        "X = encoder.transform(X_input.values)\n",
        "y = df['emotion_cluster']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: w for i, w in zip(np.unique(y_train), class_weights)}\n",
        "\n",
        "# ëª¨ë¸ ì •ì˜\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, callbacks=[early_stop], class_weight=class_weight_dict)\n",
        "\n",
        "# ì„±ëŠ¥ í‰ê°€\n",
        "y_pred = model.predict(X_val).argmax(axis=1)\n",
        "results = {\n",
        "    \"classification_report\": classification_report(y_val, y_pred, output_dict=True),\n",
        "    \"macro_f1\": f1_score(y_val, y_pred, average='macro'),\n",
        "    \"weighted_f1\": f1_score(y_val, y_pred, average='weighted')\n",
        "}\n",
        "results\n",
        "\n",
        "# ì €ì¥\n",
        "model.save('./models/final_model.keras')\n",
        "with open('./models/encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(encoder, f)\n",
        "with open('./models/note_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(note_vectorizer, f)\n",
        "note_df.to_csv('./data/note_df.csv', index=False)\n",
        "\n",
        "# ì¶”ë¡  í•¨ìˆ˜ ì •ì˜\n",
        "EMOTION_DESC = {\n",
        "    0: \"ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ ê°ì •\",\n",
        "    1: \"ì‹ ì„ í•˜ê³  í™œê¸°ì°¬ ëŠë‚Œ\",\n",
        "    2: \"ìš°ì•„í•˜ê³  ì„¸ë ¨ëœ ë¶„ìœ„ê¸°\",\n",
        "    3: \"ê´€ëŠ¥ì ì´ê³  ë§¤í˜¹ì ì¸ í–¥\",\n",
        "    4: \"ë¶€ë“œëŸ½ê³  ìˆœìˆ˜í•œ ê°ì •\",\n",
        "    5: \"ì‹ ë¹„ë¡­ê³  ë…íŠ¹í•œ ê°ì •\"\n",
        "}\n",
        "\n",
        "def predict_emotion(user_input):\n",
        "    encoder = pickle.load(open('./models/encoder.pkl', 'rb'))\n",
        "    model = load_model('./models/final_model.keras')\n",
        "    user_vec = encoder.transform([user_input])\n",
        "    proba = model.predict(user_vec)[0]\n",
        "    pred = int(np.argmax(proba))\n",
        "    return {\n",
        "        \"cluster\": pred,\n",
        "        \"description\": EMOTION_DESC[pred],\n",
        "        \"proba\": proba.tolist()\n",
        "    }\n",
        "\n",
        "def extract_notes(df, note_df, proba):\n",
        "    df['emotion_score'] = df['emotion_cluster'].map(lambda c: proba[c])\n",
        "    selected = []\n",
        "    top_sorted = df.sort_values('emotion_score', ascending=False)\n",
        "    for i in top_sorted.index:\n",
        "        if all(cosine_similarity([note_df.loc[i]], [note_df.loc[j]])[0][0] < 0.95 for j in selected):\n",
        "            selected.append(i)\n",
        "        if len(selected) == 10:\n",
        "            break\n",
        "    top_perfumes = df.loc[selected]\n",
        "    top_notes_matrix = note_df.loc[top_perfumes.index]\n",
        "    top_notes_sum = top_notes_matrix.sum(axis=0)\n",
        "    return top_notes_sum.sort_values(ascending=False).head(15).index.tolist(), selected\n",
        "\n",
        "def recommend_perfumes(df, note_df, user_note_scores, selected_idx, proba):\n",
        "    user_note_vec = np.zeros((1, len(note_df.columns)))\n",
        "    for i, note in enumerate(note_df.columns):\n",
        "        score = user_note_scores.get(note, 0)\n",
        "        user_note_vec[0, i] = score / 5\n",
        "    note_cos_sim = cosine_similarity(note_df.values, user_note_vec).reshape(-1)\n",
        "    note_sum = np.zeros(len(note_df))\n",
        "    for note, weight in user_note_scores.items():\n",
        "        if note in note_df.columns:\n",
        "            note_sum += note_df[note].to_numpy().ravel() * weight\n",
        "    note_score = 0.7 * note_cos_sim + 0.3 * (note_sum / 10)\n",
        "    df['note_score'] = note_score\n",
        "    df['is_top10'] = df.index.isin(selected_idx).astype(int)\n",
        "    df['emotion_score'] = df['emotion_cluster'].map(lambda c: proba[c])\n",
        "    df['final_score'] = 0.7 * df['emotion_score'] + 0.25 * df['note_score'] + 0.05 * df['is_top10']\n",
        "    df['note_diversity'] = note_df.astype(bool).sum(axis=1)\n",
        "    top10 = df.sort_values(by=['final_score', 'note_diversity'], ascending=[False, False]).head(10)\n",
        "    return top10[['name', 'brand', 'final_score', 'emotion_cluster']].to_dict(orient='records')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}